{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework1_181133_최유선.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 설정"
      ],
      "metadata": {
        "id": "jeA7gWZquSJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oACuLlUIqrTL"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 그래프 출력\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비"
      ],
      "metadata": {
        "id": "BcxSE0akNRKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 다운로드"
      ],
      "metadata": {
        "id": "z9-d1N5SuN2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# csv를 압축한 tgz 파일 다운로드\n",
        "# 압축 풀기 등 다운로드 작업을 자동화 -> 데이터 추출하는 함수(fetch_housing_data)\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rickiepark/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "\n",
        "# fetch_housing_data 실행\n",
        "# 현재 작업 공간에 datasets/housing 디렉터리를 생성\n",
        "# housing.tgz 파일을 내려받음\n",
        "# 압축을 푼 후 housing.csv 파일로 만듦\n"
      ],
      "metadata": {
        "id": "nqZIrcqcqsxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_housing_data()"
      ],
      "metadata": {
        "id": "k0XZTGxIuQ3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# housing.csv 불러오기\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "7S6vzAG3w3m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 분포 출력"
      ],
      "metadata": {
        "id": "V1DdcPRNHyEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10개의 특성을 가짐\n",
        "sw181133 = load_housing_data()\n",
        "sw181133.head()"
      ],
      "metadata": {
        "id": "o3d6YpTYw7-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# info() 메서드\n",
        "# 데이터에 대한 간략한 설명, 전체 행 수, 각 특성의 데이터 타입, null이 아닌 값의 개수\n",
        "sw181133.info()\n",
        "# 대부분이 수치형 데이터\n",
        "# ocean_proximity 필드가 유일한 범주형 데이터 -> 확인 필요"
      ],
      "metadata": {
        "id": "Zh3rMNW9ygxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 종류와 카테고리당 구역(행)의 수\n",
        "sw181133[\"ocean_proximity\"].value_counts()"
      ],
      "metadata": {
        "id": "NM_vbF42zH3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자형 특성의 요약 정보\n",
        "sw181133.describe()"
      ],
      "metadata": {
        "id": "bXolUZGVzsia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 숫자형 특성에 대한 히스토그램\n",
        "# 주어진 값의 범위(수평축), 샘플 수(수직축)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "sw181133.hist(bins=50, figsize=(20,15))\n",
        "save_fig(\"attribute_histogram_plots\")\n",
        "plt.show()\n",
        "\n",
        "# 중간 소득 특성이 US 달러로 표현되어 있지 않음\n",
        "# median_house_value의 상한값(최대값)이 있어서 예측이 이 값을 넘지 않는다.\n",
        "# 해결 1. 한계값 밖의 정확한 값 알아내기\n",
        "# 해결 2. 훈련세트/테스트세트에서 제거\n",
        "# 전체적으로 특성들의 스케일이 다름 -> 제대로 특성이 반영이 안됨\n",
        "# 특성이 왼쪽보다 오른쪽으로 멀리 뻗어 있음 -> 분포 조정 필요"
      ],
      "metadata": {
        "id": "PBJfImU--Ij4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 세트 생성"
      ],
      "metadata": {
        "id": "9uGnX5UmAIIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 스누핑 편향(data snooping)\n",
        "* 테스트 세트로 일반화 오차를 추정 -> 낙관적인 추정이 됨\n",
        "* 특정 머신러닝 모델을 선택하게 됨으로써 시스템 론칭 시 기대한 성능이 안 나옴"
      ],
      "metadata": {
        "id": "0YKUNJCEAXPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행 값이 동일하도록 random seed 값 고정\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "803TFhrh-Wth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 무작위로 어떤 샘플을 선택해서 데이터 세트의 20% 분할\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "metadata": {
        "id": "qfWqjB5YAL0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = split_train_test(sw181133, 0.2)\n",
        "len(train_set)"
      ],
      "metadata": {
        "id": "BErZ0jBhBP02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "id": "dlhjYhv_BTBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 코드를 다시 실행하면 다른 테스트 세트가 생성됨\n",
        "# 여러 번 계속하게 되면 전체 데이터 세트를 보는 것과 마찬가지이므로 다른 방법이 필요함\n",
        "# 해결 1. 처음 실행에서 테스트 세트를 저장하고 다음번 실행에 불러오기\n",
        "# 해결 2. 항상 같은 난수 인덱스가 생성되도록 np.random.permutation() 호출 전에 난수 발생기의 초깃값을 지정\n",
        "# 두 해법 모두 다음번에 업데이트된 데이터 세트를 사용하려면 문제가 생김\n",
        "\n",
        "# 해결책 -> 샘플의 식별자를 사용하여 테스트 세트에 보낼지 말지 정하는 것\n",
        "# ex) 각 샘플마다 식별자의 해시값을 계산하여 해시 최댓값의 20%보다 작거나 같은 샘플만 테스트 세트로 보냄\n",
        "# 여러 번 반복 실행되어 데이터 세트가 갱신되더라도 테스트 세트가 동일하게 유지됨\n",
        "# 새로운 테스트 세트는 샘플의 20%를 갖게 되나, 이전에 훈련 세트에 있던 샘플은 포함시키지 않음\n",
        "\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "    "
      ],
      "metadata": {
        "id": "SYZM9d3-E3GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n",
        "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio"
      ],
      "metadata": {
        "id": "XA_rthsuFcS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n",
        "    return bytearray(hash(np.int64(identifier)).digest())[-1] < 256 * test_ratio"
      ],
      "metadata": {
        "id": "TSC7T1u_Hbuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주택 데이터 세트에는 식별자 컬럼이 없음 -> 행의 인덱스를 id로 사용\n",
        "housing_with_id = sw181133.reset_index()  # index 열이 추가된 데이터프레임을 반환\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ],
      "metadata": {
        "id": "THFxU5eNHpWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 행의 인덱스를 고유 식별자로 사용할 때 새 데이터는 데이터 세트의 끝에 추가되어야 함\n",
        "# 고유 식별자를 만드는 데 안전한 특성을 사용해야 함, ex) 위도/경도 \n",
        "housing_with_id[\"id\"] = sw181133[\"longitude\"] * 1000 + sw181133[\"latitude\"]\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ],
      "metadata": {
        "id": "iRjlFesVHr3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.head"
      ],
      "metadata": {
        "id": "3BTz8TagHu6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_test_split()\n",
        "# 무작위 샘플링에 의한 훈련/테스트 분할\n",
        "# random_state : 난수 초기값 지정\n",
        "# 행의 개수가 같은 여러 개의 데이터 세트를 넘겨서 같은 인덱스 기반으로 나눌 수 있음\n",
        "# 데이터프레임이 레이블을 따라 여러 개로 나뉘어 있을 때 유용\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(sw181133, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "g3Z8UPyMH1Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.head()"
      ],
      "metadata": {
        "id": "-utSFnrwH-Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간소득의 카테고리 빈도에 따라 훈련세트/테스트세트 조정\n",
        "sw181133[\"median_income\"].hist()"
      ],
      "metadata": {
        "id": "8V8Lx76JKgEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.cut으로 5개 소득 카테고리 지정\n",
        "# 카테고리 레이블 1은 0에서 1.5까지 범위를 의미\n",
        "# 카테고리 레이블 2는 1.5에서 3까지 범위를 의미\n",
        "\n",
        "sw181133[\"income_cat\"] = pd.cut(sw181133[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])\n"
      ],
      "metadata": {
        "id": "9qs1UEB5Kjmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "huJptsYULa1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw181133[\"income_cat\"].value_counts()"
      ],
      "metadata": {
        "id": "YOkd0tD2K25B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw181133[\"income_cat\"].hist()"
      ],
      "metadata": {
        "id": "TP56864hLDo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소득 카테고리 기반 계층 샘플링\n",
        "# 계층 샘플링을 하는 이유 -> 테스트 세트가 전체 데이터를 대표하도록 각 계층에서 올바른 수의 샘플을 추출\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(sw181133, sw181133[\"income_cat\"]):\n",
        "    strat_train_set = sw181133.loc[train_index]\n",
        "    strat_test_set = sw181133.loc[test_index]\n",
        "    "
      ],
      "metadata": {
        "id": "_9HgO4o4Lhym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트데이터에서 소득 카테고리별 빈도수\n",
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ],
      "metadata": {
        "id": "kU1Tsbj_Lkj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체데이터 카테고리별 빈도수\n",
        "# 위와 거의 수치가 비슷함을 알 수 있음\n",
        "sw181133[\"income_cat\"].value_counts() / len(sw181133)"
      ],
      "metadata": {
        "id": "5efGgOhELmux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터 세트에 있는 소득 카테고리의 비율을 측정\n",
        "def income_cat_proportions(data):\n",
        "    return data[\"income_cat\"].value_counts() / len(data)\n",
        "\n",
        "train_set, test_set = train_test_split(sw181133, test_size=0.2, random_state=42)\n",
        "\n",
        "compare_props = pd.DataFrame({\n",
        "    \"Overall\": income_cat_proportions(sw181133),\n",
        "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
        "    \"Random\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
        "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
      ],
      "metadata": {
        "id": "Mp_5M415MCtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 계층 샘플링을 사용해 만든 테스트 세트가 전체 데이터 세트에 있는 소득 카테고리의 비율과 거의 같음\n",
        "# 전체/계층 샘플링/무작위 샘플링/무작위 샘플링 오류율/계층 샘플링 오류율\n",
        "compare_props"
      ],
      "metadata": {
        "id": "yUfRocdqMLxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# income_cat 특성 삭제\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xFCLXtENMNuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 상관관계 출력"
      ],
      "metadata": {
        "id": "ggWKj4ivPAAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 표준상관계수(피어슨 상관계수)\n",
        "corr_matrix = sw181133.corr()"
      ],
      "metadata": {
        "id": "B8jcolEuO7cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간주택 가격과 다른 특성 사이의 상관관계 크기\n",
        "# 관계 범위 -1 1\n",
        "# 1에 가까우면 양의 상관관계, 한쪽이 올라가면 같이 증가\n",
        "# 계수가 0에 가까우면 선형적인 상관관계가 없음\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "omoFdX6ZPFdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 값 사이를 산점도로 파악\n",
        "# 대각선은 자신에 대한 히스토그램\n",
        "# 숫자형 특성 사이의 산점도를 그려줌\n",
        "# 중간 주택 가격을 예측하는데 가장 유용한 것은 중간 소득임을 알 수 있음\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(sw181133[attributes], figsize=(12, 8))\n",
        "save_fig(\"scatter_matrix_plot\")"
      ],
      "metadata": {
        "id": "4m2s5D5zPbkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상관관계가 비교적 강함\n",
        "# 가격 제한값이 설정돼있음\n",
        "sw181133.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])\n",
        "save_fig(\"income_vs_house_value_scatterplot\")"
      ],
      "metadata": {
        "id": "pUM_Vv4VP1F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새로운 feature 추가"
      ],
      "metadata": {
        "id": "YSZEyupISvHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가구 수 대비 방의 개수\n",
        "# 전체방 수 대비 침실 수\n",
        "# 가구 수 대비 인구 수\n",
        "sw181133[\"rooms_per_household\"] = sw181133[\"total_rooms\"]/sw181133[\"households\"]\n",
        "sw181133[\"bedrooms_per_room\"] = sw181133[\"total_bedrooms\"]/sw181133[\"total_rooms\"]\n",
        "sw181133[\"population_per_household\"]=sw181133[\"population\"]/sw181133[\"households\"]"
      ],
      "metadata": {
        "id": "2u33shtrSPQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존의 것보다는 특성 조합한 게 상관관계가 더 높게 나옴\n",
        "# 전체방 수 대비 침실 수가 낮으면 집값이 더 비싸다 -> 음의 상관관계\n",
        "corr_matrix = sw181133.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "EPgSdBhuS3iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파이프라인 설계"
      ],
      "metadata": {
        "id": "wLANcacDUeHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**함수를 만들어 자동화해야 하는 이유**\n",
        "* 어떤 데이터 세트에 대해서도 데이터 변환을 손쉽게 반복할 수 있음\n",
        "* 향후 프로젝트에 사용할 수 있는 변환 라이브러리를 점진적으로 구축하게 됨\n",
        "* 실제 시스템에서 알고리즘에 새 데이터를 주입하기 전에 변환시키는데 이 함수를 사용할 수 있음\n",
        "* 여러 가지 데이터 변환을 쉽게 시도해볼 수 있고 어떤 조합이 가장 좋은지 확인하는 데 편리함"
      ],
      "metadata": {
        "id": "nnratu7pVKCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw181133 = strat_train_set.drop(\"median_house_value\", axis=1) # 훈련 세트를 위해 레이블 삭제\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "metadata": {
        "id": "iN8_GvkRTrIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 정제"
      ],
      "metadata": {
        "id": "-DAvNDLeW0ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "housing.dropna(subset=[\"total_bedrooms\"])    # 옵션 1\n",
        "housing.drop(\"total_bedrooms\", axis=1)       # 옵션 2\n",
        "median = housing[\"total_bedrooms\"].median()  # 옵션 3\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
        "```\n",
        "**값이 없는 경우**\n",
        "* 해당 구역을 제거\n",
        "* 전체 특성을 삭제\n",
        "* 어떤 값으로 채움 (0, 평균, 중간값)"
      ],
      "metadata": {
        "id": "9I5Zb5WJXMKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 적어도 하나의 열이 비어있는 행을 고름\n",
        "sample_incomplete_rows = sw181133[sw181133.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows"
      ],
      "metadata": {
        "id": "NeB8Aq8vU0CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# na not available\n",
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # 옵션 1"
      ],
      "metadata": {
        "id": "fsYDodaVXjMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼(열, 특성) 삭제\n",
        "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # 옵션 2"
      ],
      "metadata": {
        "id": "q0pNA7rNYCcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# median 값을 구한 후, fillna로 중간값 채우기\n",
        "median = sw181133[\"total_bedrooms\"].median()\n",
        "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # 옵션 3"
      ],
      "metadata": {
        "id": "ij_H4AXTYHtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_incomplete_rows"
      ],
      "metadata": {
        "id": "kWpw_HVEYM20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNNImputer\n",
        "# median 값으로 채움\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "metadata": {
        "id": "q2ZHn9UQYUbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간값이 수치형 특성에서만 사용될 수 있기 때문에 텍스트 특성을 삭제\n",
        "housing_num = sw181133.drop(\"ocean_proximity\", axis=1)\n",
        "# 다른 방법: housing_num = housing.select_dtypes(include=[np.number])"
      ],
      "metadata": {
        "id": "Xg_Ty51yYXkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(housing_num)"
      ],
      "metadata": {
        "id": "pdApJhq0YjnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 컬럼별 median 값\n",
        "imputer.statistics_"
      ],
      "metadata": {
        "id": "m-jWi1kDYoZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수동으로 계산한 값과 같음을 확인할 수 있음\n",
        "housing_num.median().values"
      ],
      "metadata": {
        "id": "OaARasN4Ysnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 넘파이 배열로 나옴\n",
        "X = imputer.transform(housing_num)"
      ],
      "metadata": {
        "id": "ApNgcgLmYzZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판다스 데이터프레임으로 변환\n",
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
        "                          index=housing_num.index)"
      ],
      "metadata": {
        "id": "HGNEgWqtZVi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_tr.loc[sample_incomplete_rows.index.values]"
      ],
      "metadata": {
        "id": "o8sJ28BHZXZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.strategy"
      ],
      "metadata": {
        "id": "4yPcOQ8wZaCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_tr.head()"
      ],
      "metadata": {
        "id": "hHwDYMC2Zghb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트와 범주형 특성 정제\n",
        "\n",
        "범주형 입력 특성인 `ocean_proximity`을 전처리"
      ],
      "metadata": {
        "id": "cd7pWMZFZxjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_cat = sw181133[[\"ocean_proximity\"]]\n",
        "housing_cat.head(10)"
      ],
      "metadata": {
        "id": "3nDQx5XOZjrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text를 숫자로 변환\n",
        "# OrdinalEncoder : 순서가 있고 값으로 비교 가능\n",
        "# bad average good excellent \n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "housing_cat_encoded[:10]"
      ],
      "metadata": {
        "id": "fCJI1pcVZ4V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_encoder.categories_"
      ],
      "metadata": {
        "id": "xoUzMef2Z7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 원핫인코딩 적용"
      ],
      "metadata": {
        "id": "DPvGZ37KL2Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OneHotEncoder : 한 특성만 1이고 나머지는 0, 기본적으로 희소행렬로 반환\n",
        "# sparse 행렬로 저장 : 0이 아닌 위치만 저장 \n",
        "# 희소행렬로 만들면 메모리 사이즈가 줄어 쉽게 불러오기 가능\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ],
      "metadata": {
        "id": "UjE11KEFaep1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# toarray()를 사용해 밀집 행렬로 반환\n",
        "housing_cat_1hot.toarray()"
      ],
      "metadata": {
        "id": "UdPiV6qmagsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sparse를 False로 설정해줌\n",
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ],
      "metadata": {
        "id": "kag46juMazTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 리스트 보기\n",
        "cat_encoder.categories_"
      ],
      "metadata": {
        "id": "efT7ik2Ba-Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 나만의 변환기"
      ],
      "metadata": {
        "id": "i0hc7t0rbC-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 조합 특성을 추가하는 변환기\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# 열 인덱스\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room=True): # *args 또는 **kargs 없음\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self  # 아무것도 하지 않습니다\n",
        "    def transform(self, X):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household,\n",
        "                         bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(sw181133.to_numpy())"
      ],
      "metadata": {
        "id": "p5JIqkfvbAic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_extra_attribs = pd.DataFrame(\n",
        "    housing_extra_attribs,\n",
        "    columns=list(sw181133.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
        "    index=sw181133.index)\n",
        "housing_extra_attribs.head()"
      ],
      "metadata": {
        "id": "jqHdfpQW9DMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변환 파이프라인 & 스케일링\n",
        "\n",
        "수치형 특성을 전처리하기 위해 파이프라인"
      ],
      "metadata": {
        "id": "_aU9yijx9M7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CombinedAttributesAdder : 특성을 붙임\n",
        "# 연속된 변환을 순서대로 처리할 수 있도록 도와주는 Pipeline 클래스\n",
        "# 숫자 특성을 처리하는 간단한 파이프라인\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "metadata": {
        "id": "Kg5uqREX9I1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 변환기로 각 열마다 다른 변환 적용\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "# 전체 주택 데이터를 받아 각 열에 적절한 변환을 적용하는 전처리 파이프라인 생성\n",
        "# 수치형 특성은 num_pipeline을 사용해 변환되고 범주형 특성은 OneHotEncoder를 사용해 변환됨\n",
        "# ColumnTransformer이 밀집도(0이 아닌 원소의 비율)가 임계값보다 낮으면 희소행렬로 반환\n",
        "# num_pipeline은 밀집행렬, OneHotEncoder는 희소행렬 반환\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(sw181133)"
      ],
      "metadata": {
        "id": "unOBJGuE9SS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 선택과 훈련"
      ],
      "metadata": {
        "id": "UbE3f17e-zaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형회귀 모델 적용"
      ],
      "metadata": {
        "id": "fpnKj0Cp-6Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 생성\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "DRDxgxC1-dvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 샘플 몇 개를 사용해 전체 파이프라인을 적용\n",
        "some_data = sw181133.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"예측:\", lin_reg.predict(some_data_prepared))"
      ],
      "metadata": {
        "id": "_ipxdtp8-8GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제값과 비교\n",
        "print(\"레이블:\", list(some_labels))"
      ],
      "metadata": {
        "id": "iH2KMtmw-_Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse\n",
        "\n",
        "# 예측오차 68627 -> 과소적합\n",
        "# 문제점 : 특성들이 좋은 정보를 제공하지 못했거나 모델이 강력하지 못함\n",
        "# 해결법 : 강력한 모델 선택, 훈련 알고리즘에 더 좋은 특성 주입, 모델의 규제 감소\n",
        "# 이 선형 모델에서는 모델의 규제를 사용하지 않았으므로 마지막 해결법은 제외\n",
        "# 또다른 해결법 : 특성 추가(인구의 로그스케일), 다른 모델 적용"
      ],
      "metadata": {
        "id": "FRynHy-RALdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결정트리 모델 적용"
      ],
      "metadata": {
        "id": "QmcgLs59KHmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결정트리\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "Wwo86e7FAP-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오차가 0\n",
        "# 훈련데이터 과적합\n",
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "metadata": {
        "id": "bBKFDiUoBO7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 검증"
      ],
      "metadata": {
        "id": "1zSB-WZmBkPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결정트리 교차검증\n",
        "# 교차검증에서 scoring을 효용함수(클수록 좋은 값)로 계산\n",
        "# K겹 교차검증, 훈련 세트를 폴드라 불리는 10개의 서브셋으로 무작위로 분할\n",
        "# 매번 다른 폴드를 선택해 평가에 사용하고 나머지 9개 폴드는 훈련에 사용\n",
        "# 결정 트리 모델을 10번 훈련하고 평가함\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ],
      "metadata": {
        "id": "ilTQiUrUBV_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_scores(scores):\n",
        "    print(\"점수:\", scores)\n",
        "    print(\"평균:\", scores.mean())\n",
        "    print(\"표준 편차:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)\n",
        "\n",
        "# 각 훈련의 평균과 표준편차를 통해 모델의 성능과 추정이 얼마나 정확한지 추정"
      ],
      "metadata": {
        "id": "abVn-AFpBnnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 교차검증\n",
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "metadata": {
        "id": "YWC2t2bNCR6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결정트리 모델이 과대적합되어 선형 회귀 모델보다 성능이 나쁨"
      ],
      "metadata": {
        "id": "cBqFUuO7CaRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤포레스트 모델 적용"
      ],
      "metadata": {
        "id": "abw9L1-IKLn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 100개의 트리 생성\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "ivZHlkgkCm8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤포레스트 RMSE 계산\n",
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "metadata": {
        "id": "5QZz69-yCp0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 학습 : 여러 다른 모델을 모아서 하나의 모델을 만드는 것, 머신러닝 알고리즘의 성능을 극대화\n",
        "# 훈련 세트에 대한 점수가 검증 세트에 대한 점수보다 낮음 -> 과대적합임을 알 수 있음\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "metadata": {
        "id": "o2M6IzfdC-FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 세부 튜닝"
      ],
      "metadata": {
        "id": "cQ16hqKhDnUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그리드서치 적용"
      ],
      "metadata": {
        "id": "LOnhuCK0DpRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV는 비교적 적은 수의 조합을 탐구할 때 좋음\n",
        "# 모델을 세부적으로 튜닝하는 법 -> 만족할 만한 하이퍼파라미터의 조합을 찾을 때까지 파라미터 값 조정\n",
        "# GridSearchCV를 이용해 탐색하고자 하는 하이퍼파라미터와 시도해볼 값을 지정\n",
        "# 모든 하이퍼파라미터 조합에 대해 교차 검증을 사용해 평가\n",
        "# RandomForestRegressor에 대한 최적의 하이퍼파라미터 조합을 탐색\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # 12(=3×4)개의 하이퍼파라미터 조합을 시도\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # bootstrap은 False로 하고 6(=2×3)개의 조합을 시도\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "# 다섯 개의 폴드로 훈련하면 총 (12+6)*5=90번의 훈련이 일어남\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "oPL8X4nFDB6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최상의 조합 보기\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "_RRodmfYDuLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적치 추정기\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "l5uRRVLqDxtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리드서치를 통해 테스트한 하이퍼파라미터 조합 평가 점수\n",
        "# n_estimators가 30, max_features가 8일 때 최적의 솔루션\n",
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "metadata": {
        "id": "BRBKps-eE-3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(grid_search.cv_results_)"
      ],
      "metadata": {
        "id": "aD8wo_OUFA9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤서치 적용"
      ],
      "metadata": {
        "id": "Wnzl029YFO4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV는 하이퍼파라미터의 탐색 공간이 커지면 사용하는 편\n",
        "# 가능한 모든 조합을 시도하는 대신 각 반복마다 하이퍼파라미터에 임의의 숫자 대입, 지정한 횟수만큼 평가\n",
        "# 설정값이 연속형일 경우 추천\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "1BKlwNU9FMci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ],
      "metadata": {
        "id": "zNxcBBiSFTFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최상의 모델과 오차 분석"
      ],
      "metadata": {
        "id": "wYczvQQ_GYCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ],
      "metadata": {
        "id": "vqs45XQWFVkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # 예전 방식\n",
        "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ],
      "metadata": {
        "id": "ajNYXkd0GaBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시스템 평가 / 최종 결과 출력"
      ],
      "metadata": {
        "id": "-QA3D_uRGtbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "# 훈련세트가 아니므로 fit_transform이 아닌 transform을 써야 함\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "\n",
        "# 테스트 데이터에 적용한 값이 더 낮은 경우가 일반적\n",
        "# 테스트 데이터를 위한 하이퍼 파라미터 조정은 바람직하지 않음"
      ],
      "metadata": {
        "id": "rXkpNsDWGb1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_rmse"
      ],
      "metadata": {
        "id": "Xf3drP10Gwd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}